{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `recognizer` not found.\n"
     ]
    }
   ],
   "source": [
    "# Purpose:\n",
    "\n",
    "Can I design a simple fish object recognizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Can I design a simple fish object recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import dlib\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"./train_exp/\"\n",
    "test_faces_folder = \"./test_exp/\"\n",
    "# Now let's do the training.  The train_simple_object_detector() function has a\n",
    "# bunch of options, all of which come with reasonable default values.  The next\n",
    "# few lines goes over some of these options.\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "# Since faces are left/right symmetric we can tell the trainer to train a\n",
    "# symmetric detector.  This helps it get the most value out of the training\n",
    "# data.\n",
    "options.add_left_right_image_flips = False\n",
    "# The trainer is a kind of support vector machine and therefore has the usual\n",
    "# SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
    "# data better but might lead to overfitting.  You must find the best C value\n",
    "# empirically by checking how well the trained detector works on a test set of\n",
    "# images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
    "# few different C values and see what works best for your data.\n",
    "options.C = 5\n",
    "# Tell the code how many CPU cores your computer has for the fastest training.\n",
    "options.num_threads = 4\n",
    "options.be_verbose = True\n",
    "\n",
    "\n",
    "training_xml_path = os.path.join(faces_folder, \"fish_train_ds_01.xml\")\n",
    "testing_xml_path = os.path.join(test_faces_folder, \"fish_test_ds_01.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dlib.train_simple_object_detector(training_xml_path, \"detector.svm\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: precision: 1, recall: 0.0444444, average precision: 0.0444444\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"detector.svm\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First trial not that successful. Let me reduce complexity by converting to black and white images and making image resolution same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "from os.path import isfile, join\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"../Anthony/train_exp_2\"\n",
    "test_path = \"../Anthony/test_exp_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "test_files = [f for f in listdir(test_path) if isfile(join(test_path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_grey_scale(path, files):\n",
    "    for file in files:\n",
    "        cur_file_loc = \"{0}/{1}\".format(path, file)\n",
    "        img = Image.open(cur_file_loc).convert('L')\n",
    "        img.save(cur_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_grey_scale(test_path, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"./train_exp_2/\"\n",
    "test_faces_folder = \"./test_exp_2/\"\n",
    "# Now let's do the training.  The train_simple_object_detector() function has a\n",
    "# bunch of options, all of which come with reasonable default values.  The next\n",
    "# few lines goes over some of these options.\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "# Since faces are left/right symmetric we can tell the trainer to train a\n",
    "# symmetric detector.  This helps it get the most value out of the training\n",
    "# data.\n",
    "options.add_left_right_image_flips = False\n",
    "# The trainer is a kind of support vector machine and therefore has the usual\n",
    "# SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
    "# data better but might lead to overfitting.  You must find the best C value\n",
    "# empirically by checking how well the trained detector works on a test set of\n",
    "# images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
    "# few different C values and see what works best for your data.\n",
    "options.C = 5\n",
    "# Tell the code how many CPU cores your computer has for the fastest training.\n",
    "options.num_threads = 4\n",
    "options.be_verbose = True\n",
    "\n",
    "\n",
    "training_xml_path = os.path.join(faces_folder, \"fish_train_ds_01.xml\")\n",
    "testing_xml_path = os.path.join(test_faces_folder, \"fish_test_ds_01.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dlib.train_simple_object_detector(training_xml_path, \"detector.svm\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: precision: 1, recall: 0.0540541, average precision: 0.0540541\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"detector.svm\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still abysmal, but ever so slightly better. I bet this has to do with the different resolutions. I remember some ML people talking about different resolution cameras giving the team a lot of trouble for VSM based image recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"../Anthony/train_exp_3\"\n",
    "test_path = \"../Anthony/test_exp_3\"\n",
    "train_files = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "test_files = [f for f in listdir(test_path) if isfile(join(test_path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_set_size(path, files, base_size):\n",
    "    for file in files:\n",
    "        cur_file_loc = \"{0}/{1}\".format(path, file)\n",
    "        img = Image.open(cur_file_loc)\n",
    "        print(img.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n",
      "{'jfif_density': (1, 1), 'jfif_unit': 0, 'jfif_version': (1, 1), 'jfif': 257}\n"
     ]
    }
   ],
   "source": [
    "to_set_size(train_path, train_files, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
