{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "\n",
    "Can I design a simple fish object recognizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I design a simple fish object recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import dlib\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"./train_exp/\"\n",
    "test_faces_folder = \"./test_exp/\"\n",
    "# Now let's do the training.  The train_simple_object_detector() function has a\n",
    "# bunch of options, all of which come with reasonable default values.  The next\n",
    "# few lines goes over some of these options.\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "# Since faces are left/right symmetric we can tell the trainer to train a\n",
    "# symmetric detector.  This helps it get the most value out of the training\n",
    "# data.\n",
    "options.add_left_right_image_flips = False\n",
    "# The trainer is a kind of support vector machine and therefore has the usual\n",
    "# SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
    "# data better but might lead to overfitting.  You must find the best C value\n",
    "# empirically by checking how well the trained detector works on a test set of\n",
    "# images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
    "# few different C values and see what works best for your data.\n",
    "options.C = 5\n",
    "# Tell the code how many CPU cores your computer has for the fastest training.\n",
    "options.num_threads = 4\n",
    "options.be_verbose = True\n",
    "\n",
    "\n",
    "training_xml_path = os.path.join(faces_folder, \"fish_train_ds_01.xml\")\n",
    "testing_xml_path = os.path.join(test_faces_folder, \"fish_test_ds_01.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dlib.train_simple_object_detector(training_xml_path, \"detector.svm\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: precision: 1, recall: 0.0444444, average precision: 0.0444444\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"detector.svm\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First trial not that successful. Let me reduce complexity by converting to black and white images and making image resolution same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "from os.path import isfile, join\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"../Anthony/train_exp_2\"\n",
    "test_path = \"../Anthony/test_exp_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "test_files = [f for f in listdir(test_path) if isfile(join(test_path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_grey_scale(path, files):\n",
    "    for file in files:\n",
    "        cur_file_loc = \"{0}/{1}\".format(path, file)\n",
    "        img = Image.open(cur_file_loc).convert('L')\n",
    "        img.save(cur_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_grey_scale(test_path, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"./train_exp_2/\"\n",
    "test_faces_folder = \"./test_exp_2/\"\n",
    "# Now let's do the training.  The train_simple_object_detector() function has a\n",
    "# bunch of options, all of which come with reasonable default values.  The next\n",
    "# few lines goes over some of these options.\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "# Since faces are left/right symmetric we can tell the trainer to train a\n",
    "# symmetric detector.  This helps it get the most value out of the training\n",
    "# data.\n",
    "options.add_left_right_image_flips = False\n",
    "# The trainer is a kind of support vector machine and therefore has the usual\n",
    "# SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
    "# data better but might lead to overfitting.  You must find the best C value\n",
    "# empirically by checking how well the trained detector works on a test set of\n",
    "# images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
    "# few different C values and see what works best for your data.\n",
    "options.C = 5\n",
    "# Tell the code how many CPU cores your computer has for the fastest training.\n",
    "options.num_threads = 4\n",
    "options.be_verbose = True\n",
    "\n",
    "\n",
    "training_xml_path = os.path.join(faces_folder, \"fish_train_ds_01.xml\")\n",
    "testing_xml_path = os.path.join(test_faces_folder, \"fish_test_ds_01.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dlib.train_simple_object_detector(training_xml_path, \"detector.svm\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: precision: 1, recall: 0.0540541, average precision: 0.0540541\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"detector.svm\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still abysmal, but ever so slightly better. I bet this has to do with the different resolutions. I remember some ML people talking about different resolution cameras giving the team a lot of trouble for VSM based image recognition. Also maybe fish are too complex and different, perhaps if I just use the fish face, which is more constant that can lead to a better outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faces_folder = \"./train_exp_3/\"\n",
    "test_faces_folder = \"./test_exp_3/\"\n",
    "# Now let's do the training.  The train_simple_object_detector() function has a\n",
    "# bunch of options, all of which come with reasonable default values.  The next\n",
    "# few lines goes over some of these options.\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "# Since faces are left/right symmetric we can tell the trainer to train a\n",
    "# symmetric detector.  This helps it get the most value out of the training\n",
    "# data.\n",
    "options.add_left_right_image_flips = False\n",
    "# The trainer is a kind of support vector machine and therefore has the usual\n",
    "# SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
    "# data better but might lead to overfitting.  You must find the best C value\n",
    "# empirically by checking how well the trained detector works on a test set of\n",
    "# images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
    "# few different C values and see what works best for your data.\n",
    "options.C = 5\n",
    "# Tell the code how many CPU cores your computer has for the fastest training.\n",
    "options.num_threads = 4\n",
    "options.be_verbose = True\n",
    "\n",
    "\n",
    "training_xml_path = os.path.join(faces_folder, \"fish_train_ds_01.xml\")\n",
    "testing_xml_path = os.path.join(test_faces_folder, \"fish_test_ds_01.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlib.train_simple_object_detector(training_xml_path, \"detector.svm\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: precision: 1, recall: 0.030303, average precision: 0.030303\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}\".format(\n",
    "    dlib.test_simple_object_detector(testing_xml_path, \"detector.svm\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe my dataset is too small. But just using fish faces does not lead to improvement. However, I am able to get rid of these error messages talking about an impossible set of bounding boxes. Perhaps for this rather dirty dataset, it is better to skip HOG-SVM-based fish recognition, and either use some pre-trained model directly or use deep learning for identifying a fish first and then use that result to identify what fish it is. \n",
    "\n",
    "It is well possible that my hole approach of only using 50 or so images was too little data to fit. I wanted to limit the number of boxes I had to draw. Tong mentioned that there is a kernel on Kaggle where someone actually labeled all the fish pictures. So it may still be possible to use that dataset.\n",
    "\n",
    "This much is clear: The quick win that the blog post referred to for human face recognition is not to be had with fish images.\n",
    "\n",
    "For tonight, I will focus on exploring just a different netowrk topology for deep learning. To reduce the barrier of entry, I will probably make use of a kernel that's already out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"../Anthony/train_exp_3\"\n",
    "test_path = \"../Anthony/test_exp_3\"\n",
    "train_files = [f for f in listdir(train_path) if isfile(join(train_path,f))]\n",
    "test_files = [f for f in listdir(test_path) if isfile(join(test_path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_set_size(path, files, base_size):\n",
    "    for file in files:\n",
    "        cur_file_loc = \"{0}/{1}\".format(path, file)\n",
    "        img = Image.open(cur_file_loc)\n",
    "        print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1518, 854)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 750)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 750)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 750)\n",
      "(1280, 720)\n"
     ]
    }
   ],
   "source": [
    "to_set_size(train_path, train_files, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1518, 854)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 750)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 750)\n",
      "(1280, 974)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 720)\n",
      "(1280, 974)\n",
      "(1280, 750)\n",
      "(1280, 720)\n"
     ]
    }
   ],
   "source": [
    "to_set_size(train_path, train_files, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
